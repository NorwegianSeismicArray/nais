<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>nais.Datareader API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>nais.Datareader</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import tensorflow as tf
import numpy as np
import math
from scipy.signal import convolve, tukey, triang, fftconvolve, oaconvolve
from scipy.signal.windows import gaussian

from scipy.ndimage import gaussian_filter1d

class AugmentWaveformSequence(tf.keras.utils.Sequence):

    def __init__(self,
                 x_set,
                 y_set,
                 event_type,
                 detection=None,
                 snr=None,
                 ids=None,
                 metadata_df=None,
                 metadata_cols=None,
                 batch_size=32,
                 y_type=&#39;single&#39;,
                 norm_mode=&#39;max&#39;,
                 norm_channel_mode=&#39;local&#39;,
                 augmentation=False,
                 ramp=0,
                 fill_value=0.0,
                 taper_alpha=0.0,
                 add_event=0.0,
                 add_gap=0.0,
                 max_gap_size=0.1,
                 coda_ratio=0.4,
                 new_length=None,
                 add_noise=0.0,
                 drop_channel=0.0,
                 scale_amplitude=0.0,
                 pre_emphasis=0.0,
                 min_snr=10.0,
                 add_event_space=40,
                 buffer=0,
                 model_type=&#39;phasenet&#39;,
                 shuffle=False,
                 random_crop=True,
                 create_label=False
                 ):
        &#34;&#34;&#34;
        x_set :
            numpy array, 3D, (samples, length, channels)
        y_set :
            numpy array or list of numpy arrays.
        event_type :
            list, type of event, eg. earthquake.
        snr :
            nparray, signal-to-noise for each event.
        batch_size : int, default=32
        y_type: str, default=&#39;single&#39;
            single value or waveform (eg. autoencoders, p/s picking etc).
            &#39;single&#39;: single pick, y is single value
            &#39;region&#39;: region of data, y is tuple of start and end
        norm_mode:
            str, max or std
        augmentation :
            bool
        add_event :
            float, stack events at prob.
        add_gap :
            float, mask data to zeros in period at prob.
        max_gap_size :
            float, max zeros gap in data. Proportion.
        coda_ration :
            float
        shift_event :
            float, move arrivals at prob.
        drop_channel :
            float, drop channel at prob.
        scale_amplitude :
            float, scale amplitude at prob.
        pre_emphasis :
            float
        min_snr :
            float, minimum snr required to perform augmentation.
        buffer :
            minimum steps from start of windown to p-arrival.
        shuffle :
            bool, shuffle the dataset on epoch end.
        &#34;&#34;&#34;
        self.x, self.y = x_set, y_set
        self.detection = detection
        self.num_channels = self.x.shape[-1]
        self.y_type = y_type
        self.event_type = event_type
        self.model_type = model_type
        if snr is None:
            snr = np.zeros(x_set.shape[0])
        self.snr = snr
        self.taper_alpha = taper_alpha
        self.fill_value = fill_value

        self.ids = ids
        self.metadata_df = metadata_df
        self.metadata_cols = metadata_cols

        if new_length is None:
            self.new_length = int(0.8 * self.x.shape[1])
        else:
            self.new_length = new_length

        if not (isinstance(self.y, list) or not isinstance(self.y, tuple)):
            self.y = [self.y]
            self.y_type = [self.y_type]

        self.detection_index = -1
        self.phase_index = np.arange(len(y_set))

        self.random_crop = random_crop
        self.add_event_space = add_event_space
        self.norm_mode = norm_mode
        self.norm_channel_mode = norm_channel_mode
        self.batch_size = batch_size
        self.min_snr = min_snr
        self.shuffle = shuffle
        self.p_buffer = buffer
        self.augmentation = augmentation
        self.add_event = add_event
        self.add_gap = add_gap
        self.max_gap_size = max_gap_size
        self.coda_ratio = coda_ratio
        self.add_noise = add_noise
        self.drop_channel = drop_channel
        self.scale_amplitude = scale_amplitude
        self.pre_emphasis = pre_emphasis
        self.ramp = ramp
        self.create_label = create_label
        self.non_noise_events = np.where(self.event_type != &#39;noise&#39;)[0]

        self.on_epoch_end()

    def __len__(self):
        return int(np.floor(len(self.event_type) / self.batch_size))

    def __getitem__(self, item):
        indexes = self.indexes[item * self.batch_size:(item + 1) * self.batch_size]
        X, y = zip(*list(map(self.data_generation, indexes)))
        y = np.stack(y, axis=0)
        y = np.split(y, y.shape[-1], axis=-1)
        if not self.metadata_df is None:
            m = [self.metadata_df.loc[i, self.metadata_cols].values.astype(&#39;float&#39;) if i in self.metadata_df.index else np.ones(len(self.metadata_cols))*self.fill_value for i in self.ids[indexes]]
            return np.stack(X, axis=0), y, np.stack(m, axis=0).reshape((-1, len(self.metadata_cols)))
        else:
            return np.stack(X, axis=0), y

    def on_epoch_end(self):
        &#34;&#34;&#34;Updates indexes after each epoch&#34;&#34;&#34;
        self.indexes = np.arange(len(self.x))
        if self.shuffle:
            np.random.shuffle(self.indexes)

    def _normalize(self, X, mode=&#39;max&#39;, channel_mode=&#39;local&#39;):
        X -= np.mean(X, axis=0, keepdims=True)

        if mode == &#39;max&#39;:
            if channel_mode == &#39;local&#39;:
                m = np.max(X, axis=0, keepdims=True)
            else:
                m = np.max(X, keepdims=True)
        elif mode == &#39;std&#39;:
            if channel_mode == &#39;local&#39;:
                m = np.std(X, axis=0, keepdims=True)
            else:
                m = np.std(X, keepdims=True)
        else:
            raise NotImplementedError(
                f&#39;Not supported normalization mode: {mode}&#39;)

        m[m == 0] = 1
        return X / m

    def _scale_amplitute(self, X, rate=0.1):
        n = X.shape[-1]
        r = np.random.uniform(0, 1)
        if r &lt; rate:
            X *= np.random.uniform(size=n)[np.newaxis]
        elif r &lt; 2 * rate:
            X /= np.random.uniform(size=n)[np.newaxis]
        return X

    def _drop_channel(self, X, snr, rate):
        n = X.shape[-1]
        if np.random.uniform(0, 1) &lt; rate and snr &gt;= self.min_snr:
            c = np.random.randint(0,n)
            X[..., c] = 0
        return X

    def _drop_channel_noise(self, X, rate):
        return self._drop_channel(X, float(&#39;inf&#39;), rate)

    def _add_gaps(self, X, rate, max_size=0.1):
        l = X.shape[0]
        if np.random.uniform(0, 1) &lt; rate:
            gap_start = np.random.randint(0, int((1 - max_size) * l))
            gap_end = np.random.randint(gap_start, gap_start + int(max_size * l))
            X[gap_start:gap_end] = 0
        return X

    def _add_noise(self, X, snr, rate):
        if np.random.uniform(0, 1) &lt; rate and snr &gt;= self.min_snr:
            N = np.stack([np.random.normal(loc=np.random.uniform(0.01, 0.15) * m, size=X.shape[0]) for m in X.max(axis=0)], axis=-1)
            X += N
        return X

    def _adjust_amplitute_for_multichannels(self, X):
        t = np.max(np.abs(X), axis=0, keepdims=True)
        nt = np.count_nonzeros(t)
        if nt &gt; 0:
            X *= X.shape[-1] / nt
        return nt

    def _triangular_label(self, a=0, b=20, c=40):

        z = np.linspace(a, c, num=2 * (b - a) + 1)
        y = np.zeros_like(z)
        y[z &lt;= a] = 0
        y[z &gt;= c] = 0
        first_half = np.logical_and(a &lt; z, z &lt;= b)
        y[first_half] = (z[first_half] - a) / (b - a)
        second_half = np.logical_and(b &lt; z, z &lt; c)
        y[second_half] = (c - z[second_half]) / (c - b)
        return y

    def _add_event(self, X1, detection1, X2, detection2, snr, rate, space=10):
        # Add a second event into empty part of trace.
        start1, end1 = detection1
        start2, end2 = detection2
        event2 = X2[start2:end2]
        event2_size = end2 - start2
        r = np.random.uniform(0, 1)
        scale = 0
        if r &lt; rate and snr &gt;= self.min_snr:
            scale = 1 / np.random.uniform(1, 10)
            before = np.random.choice([True, False])
            after = not before

            space_before = start1 - space
            space_after = len(X1) - end1 - space

            if event2_size &lt; space_before and before:
                # before first event
                left_over = space_before - event2_size
                if left_over - space &gt; 0:
                    s = np.random.randint(0, left_over-space)
                    e = s + len(event2)
                    X1[s:e] += event2 * scale

            elif event2_size &lt; space_after and after:
                # after first event
                left_over = space_after - event2_size
                if left_over &gt; space:
                    s = np.random.randint(space, left_over)
                    e = s + len(event2)
                    X1[end1+s:end1+e] += event2 * scale

        return X1, scale

    def _shift_crop(self, img, mask):
        if self.random_crop:
            y1 = np.random.randint(0, len(img) - self.new_length)
        else:
            y1 = int((len(img) - self.new_length) / 2)

        img = img[y1:y1 + self.new_length]
        mask = mask[y1:y1 + self.new_length]
        return img, mask

    def _taper(self, img, mask, alpha=0.1):
        w = tukey(img.shape[0], alpha)
        return img*w[:,np.newaxis], mask

    def _pre_emphasis(self, X, pre_emphasis=0.97):
        return np.stack([np.append(X[0,c], X[1:,c] - pre_emphasis * X[:-1,c]) for c in range(X.shape[1])], axis=-1)

    def _convert_y_to_regions(self, y, yt, label):
        for j in range(len(y)):
            if yt[j] == &#39;single&#39;:
                i = y[j]
                if not math.isnan(i):
                    label[int(i),j] = 1
            elif yt[j] == &#39;region&#39;:
                start, end = y[j]
                if not (math.isnan(start) or math.isnan(end)):
                    start, end = map(int, (start, end))
                    start = max(0, start)
                    end = min(len(label), end)
                    detection = (start, end)
                    label[start:end,j] = 1
            else:
                raise NotImplementedError(yt[j] + &#39; is not supported.&#39;)

        if self.ramp &gt; 0:
            label = gaussian_filter1d(label, sigma=self.ramp, axis=0)

        m = np.amax(label, axis=0, keepdims=True)
        m[m == 0] = 1
        label /= m

        if not &#39;detection&#39; in locals():
            detection = (len(label)//4,3*len(label)//4)

        return label, detection

    def data_generation(self, idx):

        x = self.x[idx]
        y = [a[idx] for a in self.y]
        if self.create_label:
            label = np.zeros((x.shape[0],len(self.y_type)))
            label, detection = self._convert_y_to_regions(y, self.y_type, label)
        else:
            detection = self.detection[idx]
            label = np.concatenate([np.expand_dims(detection, axis=-1), np.stack(y, axis=-1)], axis=-1)

        do_aug = self.augmentation and np.random.random() &gt; 0.5
        if do_aug:
            if self.event_type[idx] == &#39;noise&#39;:
                if self.drop_channel &gt; 0:
                    x = self._drop_channel_noise(x, self.drop_channel)
                if self.add_gap &gt; 0:
                    x = self._add_gaps(
                        x, self.add_gap, max_size=self.max_gap_size)
            else:
                if self.add_event &gt; np.random.uniform(0,1) and self.snr[idx] &gt;= self.min_snr:
                    t = np.random.choice(self.non_noise_events)
                    y2 = [a[t] for a in self.y]
                    if self.create_label:
                        label2 = np.zeros((x.shape[0], len(self.y_type)))
                        label2, detection2 = self._convert_y_to_regions(y2, self.y_type, label2)
                    else:
                        detection2 = self.detection[t]
                        label2 = np.concatenate([np.expand_dims(detection2, axis=-1), np.stack(y2, axis=-1)], axis=-1)
                    roll = np.random.randint(0, label.shape[0])
                    label = np.roll(label, roll, axis=0)
                    x2 = np.roll(self.x[t], roll, axis=0)
                    scale = 1 / np.random.uniform(1, 10)
                    label = np.amax([label, label2 * scale], axis=0)
                    x = x + scale * x2

                if self.add_noise &gt; 0:
                    x = self._add_noise(x, self.snr[idx], self.add_noise)
                if self.drop_channel &gt; 0:
                    x = self._drop_channel(x, self.snr[idx], self.drop_channel)
                if self.scale_amplitude &gt; 0:
                    x = self._scale_amplitute(x, self.scale_amplitude)
                if self.pre_emphasis &gt; 0:
                    x = self._pre_emphasis(x, self.pre_emphasis)
                if self.add_gap &gt; 0:
                    x = self._add_gaps(
                        x, self.add_gap, max_size=self.max_gap_size)

        x, label = self._shift_crop(x, label)
        if self.taper_alpha &gt; 0:
            x, label = self._taper(x, label, self.taper_alpha)

        if self.norm_mode is not None:
            x = self._normalize(x, mode=self.norm_mode, channel_mode=self.norm_channel_mode)

        return x, label</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="nais.Datareader.AugmentWaveformSequence"><code class="flex name class">
<span>class <span class="ident">AugmentWaveformSequence</span></span>
<span>(</span><span>x_set, y_set, event_type, detection=None, snr=None, ids=None, metadata_df=None, metadata_cols=None, batch_size=32, y_type='single', norm_mode='max', norm_channel_mode='local', augmentation=False, ramp=0, fill_value=0.0, taper_alpha=0.0, add_event=0.0, add_gap=0.0, max_gap_size=0.1, coda_ratio=0.4, new_length=None, add_noise=0.0, drop_channel=0.0, scale_amplitude=0.0, pre_emphasis=0.0, min_snr=10.0, add_event_space=40, buffer=0, model_type='phasenet', shuffle=False, random_crop=True, create_label=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Base object for fitting to a sequence of data, such as a dataset.</p>
<p>Every <code>Sequence</code> must implement the <code>__getitem__</code> and the <code>__len__</code> methods.
If you want to modify your dataset between epochs you may implement
<code>on_epoch_end</code>.
The method <code>__getitem__</code> should return a complete batch.</p>
<p>Notes:</p>
<p><code>Sequence</code> are a safer way to do multiprocessing. This structure guarantees
that the network will only train once
on each sample per epoch which is not the case with generators.</p>
<p>Examples:</p>
<pre><code class="language-python">from skimage.io import imread
from skimage.transform import resize
import numpy as np
import math

# Here, `x_set` is list of path to the images
# and `y_set` are the associated classes.

class CIFAR10Sequence(Sequence):

    def __init__(self, x_set, y_set, batch_size):
        self.x, self.y = x_set, y_set
        self.batch_size = batch_size

    def __len__(self):
        return math.ceil(len(self.x) / self.batch_size)

    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) *
        self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) *
        self.batch_size]

        return np.array([
            resize(imread(file_name), (200, 200))
               for file_name in batch_x]), np.array(batch_y)
</code></pre>
<p>x_set :
numpy array, 3D, (samples, length, channels)
y_set :
numpy array or list of numpy arrays.
event_type :
list, type of event, eg. earthquake.
snr :
nparray, signal-to-noise for each event.
batch_size : int, default=32
y_type: str, default='single'
single value or waveform (eg. autoencoders, p/s picking etc).
'single': single pick, y is single value
'region': region of data, y is tuple of start and end
norm_mode:
str, max or std
augmentation :
bool
add_event :
float, stack events at prob.
add_gap :
float, mask data to zeros in period at prob.
max_gap_size :
float, max zeros gap in data. Proportion.
coda_ration :
float
shift_event :
float, move arrivals at prob.
drop_channel :
float, drop channel at prob.
scale_amplitude :
float, scale amplitude at prob.
pre_emphasis :
float
min_snr :
float, minimum snr required to perform augmentation.
buffer :
minimum steps from start of windown to p-arrival.
shuffle :
bool, shuffle the dataset on epoch end.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AugmentWaveformSequence(tf.keras.utils.Sequence):

    def __init__(self,
                 x_set,
                 y_set,
                 event_type,
                 detection=None,
                 snr=None,
                 ids=None,
                 metadata_df=None,
                 metadata_cols=None,
                 batch_size=32,
                 y_type=&#39;single&#39;,
                 norm_mode=&#39;max&#39;,
                 norm_channel_mode=&#39;local&#39;,
                 augmentation=False,
                 ramp=0,
                 fill_value=0.0,
                 taper_alpha=0.0,
                 add_event=0.0,
                 add_gap=0.0,
                 max_gap_size=0.1,
                 coda_ratio=0.4,
                 new_length=None,
                 add_noise=0.0,
                 drop_channel=0.0,
                 scale_amplitude=0.0,
                 pre_emphasis=0.0,
                 min_snr=10.0,
                 add_event_space=40,
                 buffer=0,
                 model_type=&#39;phasenet&#39;,
                 shuffle=False,
                 random_crop=True,
                 create_label=False
                 ):
        &#34;&#34;&#34;
        x_set :
            numpy array, 3D, (samples, length, channels)
        y_set :
            numpy array or list of numpy arrays.
        event_type :
            list, type of event, eg. earthquake.
        snr :
            nparray, signal-to-noise for each event.
        batch_size : int, default=32
        y_type: str, default=&#39;single&#39;
            single value or waveform (eg. autoencoders, p/s picking etc).
            &#39;single&#39;: single pick, y is single value
            &#39;region&#39;: region of data, y is tuple of start and end
        norm_mode:
            str, max or std
        augmentation :
            bool
        add_event :
            float, stack events at prob.
        add_gap :
            float, mask data to zeros in period at prob.
        max_gap_size :
            float, max zeros gap in data. Proportion.
        coda_ration :
            float
        shift_event :
            float, move arrivals at prob.
        drop_channel :
            float, drop channel at prob.
        scale_amplitude :
            float, scale amplitude at prob.
        pre_emphasis :
            float
        min_snr :
            float, minimum snr required to perform augmentation.
        buffer :
            minimum steps from start of windown to p-arrival.
        shuffle :
            bool, shuffle the dataset on epoch end.
        &#34;&#34;&#34;
        self.x, self.y = x_set, y_set
        self.detection = detection
        self.num_channels = self.x.shape[-1]
        self.y_type = y_type
        self.event_type = event_type
        self.model_type = model_type
        if snr is None:
            snr = np.zeros(x_set.shape[0])
        self.snr = snr
        self.taper_alpha = taper_alpha
        self.fill_value = fill_value

        self.ids = ids
        self.metadata_df = metadata_df
        self.metadata_cols = metadata_cols

        if new_length is None:
            self.new_length = int(0.8 * self.x.shape[1])
        else:
            self.new_length = new_length

        if not (isinstance(self.y, list) or not isinstance(self.y, tuple)):
            self.y = [self.y]
            self.y_type = [self.y_type]

        self.detection_index = -1
        self.phase_index = np.arange(len(y_set))

        self.random_crop = random_crop
        self.add_event_space = add_event_space
        self.norm_mode = norm_mode
        self.norm_channel_mode = norm_channel_mode
        self.batch_size = batch_size
        self.min_snr = min_snr
        self.shuffle = shuffle
        self.p_buffer = buffer
        self.augmentation = augmentation
        self.add_event = add_event
        self.add_gap = add_gap
        self.max_gap_size = max_gap_size
        self.coda_ratio = coda_ratio
        self.add_noise = add_noise
        self.drop_channel = drop_channel
        self.scale_amplitude = scale_amplitude
        self.pre_emphasis = pre_emphasis
        self.ramp = ramp
        self.create_label = create_label
        self.non_noise_events = np.where(self.event_type != &#39;noise&#39;)[0]

        self.on_epoch_end()

    def __len__(self):
        return int(np.floor(len(self.event_type) / self.batch_size))

    def __getitem__(self, item):
        indexes = self.indexes[item * self.batch_size:(item + 1) * self.batch_size]
        X, y = zip(*list(map(self.data_generation, indexes)))
        y = np.stack(y, axis=0)
        y = np.split(y, y.shape[-1], axis=-1)
        if not self.metadata_df is None:
            m = [self.metadata_df.loc[i, self.metadata_cols].values.astype(&#39;float&#39;) if i in self.metadata_df.index else np.ones(len(self.metadata_cols))*self.fill_value for i in self.ids[indexes]]
            return np.stack(X, axis=0), y, np.stack(m, axis=0).reshape((-1, len(self.metadata_cols)))
        else:
            return np.stack(X, axis=0), y

    def on_epoch_end(self):
        &#34;&#34;&#34;Updates indexes after each epoch&#34;&#34;&#34;
        self.indexes = np.arange(len(self.x))
        if self.shuffle:
            np.random.shuffle(self.indexes)

    def _normalize(self, X, mode=&#39;max&#39;, channel_mode=&#39;local&#39;):
        X -= np.mean(X, axis=0, keepdims=True)

        if mode == &#39;max&#39;:
            if channel_mode == &#39;local&#39;:
                m = np.max(X, axis=0, keepdims=True)
            else:
                m = np.max(X, keepdims=True)
        elif mode == &#39;std&#39;:
            if channel_mode == &#39;local&#39;:
                m = np.std(X, axis=0, keepdims=True)
            else:
                m = np.std(X, keepdims=True)
        else:
            raise NotImplementedError(
                f&#39;Not supported normalization mode: {mode}&#39;)

        m[m == 0] = 1
        return X / m

    def _scale_amplitute(self, X, rate=0.1):
        n = X.shape[-1]
        r = np.random.uniform(0, 1)
        if r &lt; rate:
            X *= np.random.uniform(size=n)[np.newaxis]
        elif r &lt; 2 * rate:
            X /= np.random.uniform(size=n)[np.newaxis]
        return X

    def _drop_channel(self, X, snr, rate):
        n = X.shape[-1]
        if np.random.uniform(0, 1) &lt; rate and snr &gt;= self.min_snr:
            c = np.random.randint(0,n)
            X[..., c] = 0
        return X

    def _drop_channel_noise(self, X, rate):
        return self._drop_channel(X, float(&#39;inf&#39;), rate)

    def _add_gaps(self, X, rate, max_size=0.1):
        l = X.shape[0]
        if np.random.uniform(0, 1) &lt; rate:
            gap_start = np.random.randint(0, int((1 - max_size) * l))
            gap_end = np.random.randint(gap_start, gap_start + int(max_size * l))
            X[gap_start:gap_end] = 0
        return X

    def _add_noise(self, X, snr, rate):
        if np.random.uniform(0, 1) &lt; rate and snr &gt;= self.min_snr:
            N = np.stack([np.random.normal(loc=np.random.uniform(0.01, 0.15) * m, size=X.shape[0]) for m in X.max(axis=0)], axis=-1)
            X += N
        return X

    def _adjust_amplitute_for_multichannels(self, X):
        t = np.max(np.abs(X), axis=0, keepdims=True)
        nt = np.count_nonzeros(t)
        if nt &gt; 0:
            X *= X.shape[-1] / nt
        return nt

    def _triangular_label(self, a=0, b=20, c=40):

        z = np.linspace(a, c, num=2 * (b - a) + 1)
        y = np.zeros_like(z)
        y[z &lt;= a] = 0
        y[z &gt;= c] = 0
        first_half = np.logical_and(a &lt; z, z &lt;= b)
        y[first_half] = (z[first_half] - a) / (b - a)
        second_half = np.logical_and(b &lt; z, z &lt; c)
        y[second_half] = (c - z[second_half]) / (c - b)
        return y

    def _add_event(self, X1, detection1, X2, detection2, snr, rate, space=10):
        # Add a second event into empty part of trace.
        start1, end1 = detection1
        start2, end2 = detection2
        event2 = X2[start2:end2]
        event2_size = end2 - start2
        r = np.random.uniform(0, 1)
        scale = 0
        if r &lt; rate and snr &gt;= self.min_snr:
            scale = 1 / np.random.uniform(1, 10)
            before = np.random.choice([True, False])
            after = not before

            space_before = start1 - space
            space_after = len(X1) - end1 - space

            if event2_size &lt; space_before and before:
                # before first event
                left_over = space_before - event2_size
                if left_over - space &gt; 0:
                    s = np.random.randint(0, left_over-space)
                    e = s + len(event2)
                    X1[s:e] += event2 * scale

            elif event2_size &lt; space_after and after:
                # after first event
                left_over = space_after - event2_size
                if left_over &gt; space:
                    s = np.random.randint(space, left_over)
                    e = s + len(event2)
                    X1[end1+s:end1+e] += event2 * scale

        return X1, scale

    def _shift_crop(self, img, mask):
        if self.random_crop:
            y1 = np.random.randint(0, len(img) - self.new_length)
        else:
            y1 = int((len(img) - self.new_length) / 2)

        img = img[y1:y1 + self.new_length]
        mask = mask[y1:y1 + self.new_length]
        return img, mask

    def _taper(self, img, mask, alpha=0.1):
        w = tukey(img.shape[0], alpha)
        return img*w[:,np.newaxis], mask

    def _pre_emphasis(self, X, pre_emphasis=0.97):
        return np.stack([np.append(X[0,c], X[1:,c] - pre_emphasis * X[:-1,c]) for c in range(X.shape[1])], axis=-1)

    def _convert_y_to_regions(self, y, yt, label):
        for j in range(len(y)):
            if yt[j] == &#39;single&#39;:
                i = y[j]
                if not math.isnan(i):
                    label[int(i),j] = 1
            elif yt[j] == &#39;region&#39;:
                start, end = y[j]
                if not (math.isnan(start) or math.isnan(end)):
                    start, end = map(int, (start, end))
                    start = max(0, start)
                    end = min(len(label), end)
                    detection = (start, end)
                    label[start:end,j] = 1
            else:
                raise NotImplementedError(yt[j] + &#39; is not supported.&#39;)

        if self.ramp &gt; 0:
            label = gaussian_filter1d(label, sigma=self.ramp, axis=0)

        m = np.amax(label, axis=0, keepdims=True)
        m[m == 0] = 1
        label /= m

        if not &#39;detection&#39; in locals():
            detection = (len(label)//4,3*len(label)//4)

        return label, detection

    def data_generation(self, idx):

        x = self.x[idx]
        y = [a[idx] for a in self.y]
        if self.create_label:
            label = np.zeros((x.shape[0],len(self.y_type)))
            label, detection = self._convert_y_to_regions(y, self.y_type, label)
        else:
            detection = self.detection[idx]
            label = np.concatenate([np.expand_dims(detection, axis=-1), np.stack(y, axis=-1)], axis=-1)

        do_aug = self.augmentation and np.random.random() &gt; 0.5
        if do_aug:
            if self.event_type[idx] == &#39;noise&#39;:
                if self.drop_channel &gt; 0:
                    x = self._drop_channel_noise(x, self.drop_channel)
                if self.add_gap &gt; 0:
                    x = self._add_gaps(
                        x, self.add_gap, max_size=self.max_gap_size)
            else:
                if self.add_event &gt; np.random.uniform(0,1) and self.snr[idx] &gt;= self.min_snr:
                    t = np.random.choice(self.non_noise_events)
                    y2 = [a[t] for a in self.y]
                    if self.create_label:
                        label2 = np.zeros((x.shape[0], len(self.y_type)))
                        label2, detection2 = self._convert_y_to_regions(y2, self.y_type, label2)
                    else:
                        detection2 = self.detection[t]
                        label2 = np.concatenate([np.expand_dims(detection2, axis=-1), np.stack(y2, axis=-1)], axis=-1)
                    roll = np.random.randint(0, label.shape[0])
                    label = np.roll(label, roll, axis=0)
                    x2 = np.roll(self.x[t], roll, axis=0)
                    scale = 1 / np.random.uniform(1, 10)
                    label = np.amax([label, label2 * scale], axis=0)
                    x = x + scale * x2

                if self.add_noise &gt; 0:
                    x = self._add_noise(x, self.snr[idx], self.add_noise)
                if self.drop_channel &gt; 0:
                    x = self._drop_channel(x, self.snr[idx], self.drop_channel)
                if self.scale_amplitude &gt; 0:
                    x = self._scale_amplitute(x, self.scale_amplitude)
                if self.pre_emphasis &gt; 0:
                    x = self._pre_emphasis(x, self.pre_emphasis)
                if self.add_gap &gt; 0:
                    x = self._add_gaps(
                        x, self.add_gap, max_size=self.max_gap_size)

        x, label = self._shift_crop(x, label)
        if self.taper_alpha &gt; 0:
            x, label = self._taper(x, label, self.taper_alpha)

        if self.norm_mode is not None:
            x = self._normalize(x, mode=self.norm_mode, channel_mode=self.norm_channel_mode)

        return x, label</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>keras.utils.data_utils.Sequence</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="nais.Datareader.AugmentWaveformSequence.data_generation"><code class="name flex">
<span>def <span class="ident">data_generation</span></span>(<span>self, idx)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def data_generation(self, idx):

    x = self.x[idx]
    y = [a[idx] for a in self.y]
    if self.create_label:
        label = np.zeros((x.shape[0],len(self.y_type)))
        label, detection = self._convert_y_to_regions(y, self.y_type, label)
    else:
        detection = self.detection[idx]
        label = np.concatenate([np.expand_dims(detection, axis=-1), np.stack(y, axis=-1)], axis=-1)

    do_aug = self.augmentation and np.random.random() &gt; 0.5
    if do_aug:
        if self.event_type[idx] == &#39;noise&#39;:
            if self.drop_channel &gt; 0:
                x = self._drop_channel_noise(x, self.drop_channel)
            if self.add_gap &gt; 0:
                x = self._add_gaps(
                    x, self.add_gap, max_size=self.max_gap_size)
        else:
            if self.add_event &gt; np.random.uniform(0,1) and self.snr[idx] &gt;= self.min_snr:
                t = np.random.choice(self.non_noise_events)
                y2 = [a[t] for a in self.y]
                if self.create_label:
                    label2 = np.zeros((x.shape[0], len(self.y_type)))
                    label2, detection2 = self._convert_y_to_regions(y2, self.y_type, label2)
                else:
                    detection2 = self.detection[t]
                    label2 = np.concatenate([np.expand_dims(detection2, axis=-1), np.stack(y2, axis=-1)], axis=-1)
                roll = np.random.randint(0, label.shape[0])
                label = np.roll(label, roll, axis=0)
                x2 = np.roll(self.x[t], roll, axis=0)
                scale = 1 / np.random.uniform(1, 10)
                label = np.amax([label, label2 * scale], axis=0)
                x = x + scale * x2

            if self.add_noise &gt; 0:
                x = self._add_noise(x, self.snr[idx], self.add_noise)
            if self.drop_channel &gt; 0:
                x = self._drop_channel(x, self.snr[idx], self.drop_channel)
            if self.scale_amplitude &gt; 0:
                x = self._scale_amplitute(x, self.scale_amplitude)
            if self.pre_emphasis &gt; 0:
                x = self._pre_emphasis(x, self.pre_emphasis)
            if self.add_gap &gt; 0:
                x = self._add_gaps(
                    x, self.add_gap, max_size=self.max_gap_size)

    x, label = self._shift_crop(x, label)
    if self.taper_alpha &gt; 0:
        x, label = self._taper(x, label, self.taper_alpha)

    if self.norm_mode is not None:
        x = self._normalize(x, mode=self.norm_mode, channel_mode=self.norm_channel_mode)

    return x, label</code></pre>
</details>
</dd>
<dt id="nais.Datareader.AugmentWaveformSequence.on_epoch_end"><code class="name flex">
<span>def <span class="ident">on_epoch_end</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Updates indexes after each epoch</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_epoch_end(self):
    &#34;&#34;&#34;Updates indexes after each epoch&#34;&#34;&#34;
    self.indexes = np.arange(len(self.x))
    if self.shuffle:
        np.random.shuffle(self.indexes)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="nais" href="index.html">nais</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="nais.Datareader.AugmentWaveformSequence" href="#nais.Datareader.AugmentWaveformSequence">AugmentWaveformSequence</a></code></h4>
<ul class="">
<li><code><a title="nais.Datareader.AugmentWaveformSequence.data_generation" href="#nais.Datareader.AugmentWaveformSequence.data_generation">data_generation</a></code></li>
<li><code><a title="nais.Datareader.AugmentWaveformSequence.on_epoch_end" href="#nais.Datareader.AugmentWaveformSequence.on_epoch_end">on_epoch_end</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>